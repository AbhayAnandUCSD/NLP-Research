{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f0ce24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install transformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistilBertTokenizerFast\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "!pip install transformers\n",
    "\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "###Import Dataset\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "ds = tfds.load('amazon_us_reviews/Mobile_Electronics_v1_00', split='train', shuffle_files=True)\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "\n",
    "df = tfds.as_dataframe(ds)\n",
    "\n",
    "df.head()\n",
    "\n",
    "##Create Sentiment Labels\n",
    "\n",
    "\n",
    "df[\"Sentiment\"] = df[\"data/star_rating\"].apply(lambda score: \"positive\" if score >= 3 else \"negative\")\n",
    "df['Sentiment'] = df['Sentiment'].map({'positive':1, 'negative':0})\n",
    "\n",
    "df['short_review'] =df['data/review_body'].str.decode(\"utf-8\")\n",
    "\n",
    "df = df[[\"short_review\", \"Sentiment\"]]\n",
    "\n",
    "# Dropping last n rows using drop\n",
    "n = 54975\n",
    "df.drop(df.tail(n).index,\n",
    "        inplace = True)\n",
    "\n",
    "index = df.index\n",
    "number_of_rows = len(index)\n",
    "print(number_of_rows)\n",
    "\n",
    "df.tail()\n",
    "\n",
    "reviews = df['short_review'].values.tolist()\n",
    "labels = df['Sentiment'].tolist()\n",
    "\n",
    "print(reviews[:2])\n",
    "print(labels[:2])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_sentences, validation_sentences, training_labels, validation_labels = train_test_split(reviews, labels, test_size=.2)\n",
    "\n",
    "\n",
    "# Replace \"nan\" with space\n",
    "X_train = training_sentences\n",
    "X_test = validation_sentences\n",
    "X_train_targetSentiment = training_labels\n",
    "X_test_targetSentiment = validation_labels\n",
    "\n",
    "# Text preprocessing and occurance counting\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train) \n",
    "X_train_counts.shape\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf_multiNB_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_nominalNB\", MultinomialNB())])\n",
    "clf_multiNB_pipe.fit(X_train, X_train_targetSentiment)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "predictedMultiNB = clf_multiNB_pipe.predict(X_test)\n",
    "np.mean(predictedMultiNB == X_test_targetSentiment)\n",
    "\n",
    "\n",
    "#Support Vector Machine Classifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf_linearSVC_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_linearSVC\", LinearSVC())])\n",
    "clf_linearSVC_pipe.fit(X_train, X_train_targetSentiment)\n",
    "\n",
    "predictedLinearSVC = clf_linearSVC_pipe.predict(X_test)\n",
    "np.mean(predictedLinearSVC == X_test_targetSentiment)\n",
    "\n",
    "###OUTPUT: \n",
    "0.9013\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27222f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
